I am greatly interested in the use of recurrent networks (and deep learning techniques generally) for time series analysis and forecasting. In this project, I compared the efficacy of three different recurrent neural network architectures (vanilla, LSTM, and GRU) for predicting a time series of closing IBM stock prices.

I found that, in this scenario, LSTM offered the best accuracy with only a slight tradeoff in computational time. (While the LSTM took significantly longer to train per epoch than the vanilla RNN, it required fewere epochs to train and was notably more accurate.) Surprisingly, the GRU, which is traditionally considered an ideal tradeoff between computational complexity and accuracy, perfomed worse than the LSTM model in training time per epoch, required more epochs to train, and actually performed worse in RMSE than the vanilla RNN. Part of this is a reflection of the complexity of the individual models, however.
